{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38564bitaf0a248642444d95b3308d5cb8b153d4",
   "display_name": "Python 3.8.5 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import fbeta_score\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusterization = pd.read_csv(\"data/clusterization.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wcss = []\n",
    "qtd_clus = []\n",
    "for k in range( 1, 15 ):\n",
    "    kmeans = KMeans(n_clusters=k, init=\"k-means++\", n_init=10, max_iter=300) \n",
    "    kmeans.fit_predict(clusterization)\n",
    "    wcss.append( kmeans.inertia_ )\n",
    "    qtd_clus.append( k )\n",
    "\n",
    "plt.plot(qtd_clus, wcss, 'ro-')\n",
    "plt.title(\"Estimando Quantidade de Clusters - Elbow Method\")\n",
    "plt.xlabel(\"# Clusters\")\n",
    "plt.ylabel(\"Elbow Method\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "silcoef = []\n",
    "qtd_clus = []\n",
    "\n",
    "for k in range(2,15):\n",
    "    kmeans = KMeans(n_clusters=k).fit(clusterization)\n",
    "    label = kmeans.labels_\n",
    "    sil_coeff = silhouette_score(clusterization, label, metric='euclidean')\n",
    "    silcoef.append(sil_coeff)\n",
    "    qtd_clus.append(k)\n",
    "\n",
    "pos_clus = max(enumerate(silcoef), key=(lambda x: x[1]))[0]  \n",
    "qt_clus = qtd_clus[pos_clus]\n",
    "\n",
    "\n",
    "df_coefsil = pd.DataFrame(silcoef, columns=['coefsil'])\n",
    "df_clus = pd.DataFrame(qtd_clus, columns=['nclus'])\n",
    "dfsil = df_coefsil.merge(df_clus, left_index=True, right_index=True, how = 'inner')    \n",
    "\n",
    "ax = sns.barplot(x=\"nclus\",y='coefsil', data=dfsil)\n",
    "plt.title('Analise da Quantidade de Clusters - Silhueta', y=1.05, size=15)\n",
    "plt.xlabel('Quantidade de Clusters', fontsize=14)\n",
    "plt.ylabel('Silhouette ', fontsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_model = KMeans(n_clusters=3, random_state=1).fit(clusterization)\n",
    "labels = kmeans_model.labels_\n",
    "metrics.calinski_harabaz_score(clusterization, labels)\n",
    "qtd_clus = []\n",
    "calinski_harabaz = []\n",
    "for k in range(2, 15):\n",
    "    kmeans_model = KMeans(n_clusters=k, random_state=1).fit(clusterization)\n",
    "    labels = kmeans_model.labels_\n",
    "    calinski_harabaz.append(metrics.calinski_harabaz_score(clusterization, labels))\n",
    "    qtd_clus.append(k)\n",
    "df_ch = pd.DataFrame(calinski_harabaz, columns=['calinski_harabaz'])\n",
    "df_clus = pd.DataFrame(qtd_clus, columns=['nclus'])\n",
    "dfch = df_ch.merge(df_clus, left_index=True, right_index=True, how = 'inner')  \n",
    "ax = sns.lineplot(x=\"nclus\",y='calinski_harabaz', data=dfch)\n",
    "plt.title('Analise da Quantidade de Clusters - Calinski-Harabaz', y=1.05, size=15)\n",
    "plt.xlabel('Quantidade de Clusters', fontsize=14)\n",
    "plt.ylabel('Calinski-Harabaz', fontsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_model = KMeans(n_clusters=3, random_state=1).fit(clusterization)\n",
    "labels = kmeans_model.labels_\n",
    "metrics.davies_bouldin_score(clusterization, labels)\n",
    "qtd_clus = []\n",
    "davies_bouldin = []\n",
    "for k in range(2, 15):\n",
    "    kmeans_model = KMeans(n_clusters=k, random_state=1).fit(clusterization)\n",
    "    labels = kmeans_model.labels_\n",
    "    davies_bouldin.append(metrics.davies_bouldin_score(clusterization, labels))\n",
    "    qtd_clus.append(k)\n",
    "df_db = pd.DataFrame(davies_bouldin, columns=['davies_bouldin'])\n",
    "df_clus = pd.DataFrame(qtd_clus, columns=['nclus'])\n",
    "dfdb = df_db.merge(df_clus, left_index=True, right_index=True, how = 'inner')  \n",
    "ax = sns.lineplot(x=\"nclus\",y='davies_bouldin', data=dfdb)\n",
    "plt.title('Analise da Quantidade de Clusters - Davies Bouldin', y=1.05, size=15)\n",
    "plt.xlabel('Quantidade de Clusters', fontsize=14)\n",
    "plt.ylabel('Davies Bouldin', fontsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}